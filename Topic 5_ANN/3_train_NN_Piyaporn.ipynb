{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "X_train, X_valid, X_test = X_train/255, X_valid/255, X_test/255\n",
    "# we much scale X values to 0-1 range\n",
    "# we do not need to scale y values because they are already in 0-9 range\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \n",
    "               \"Dress\", \"Coat\", \"Sandal\", \"Shirt\",\n",
    "               \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lelu\n",
    "Activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mr.Grumpy\\miniconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2024)\n",
    "model = tf.keras.models.Sequential()# emty model\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[28, 28])) # input layer\n",
    "for layer in range(100):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"lecun_normal\")) # hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\")) # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "  metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - accuracy: 0.1004 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3026\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.1019 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.1016 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.1021 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3027\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.0900 - val_loss: 2.3028\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### elu / selu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mr.Grumpy\\miniconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.2165 - loss: 2.0240 - val_accuracy: 0.4940 - val_loss: 1.1733\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.5576 - loss: 1.0751 - val_accuracy: 0.6734 - val_loss: 0.8130\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.6896 - loss: 0.7978 - val_accuracy: 0.7366 - val_loss: 0.7093\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.7414 - loss: 0.7207 - val_accuracy: 0.7604 - val_loss: 0.6668\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.7709 - loss: 0.6513 - val_accuracy: 0.7736 - val_loss: 0.6409\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2024)\n",
    "model = tf.keras.models.Sequential()# emty model\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[28, 28])) # input layer\n",
    "for layer in range(100):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"lecun_normal\")) # hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\")) # output layer\n",
    "model.compile(\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "  metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mr.Grumpy\\miniconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14ms/step - accuracy: 0.3618 - loss: 1.7129 - val_accuracy: 0.6604 - val_loss: 0.9242\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.6694 - loss: 0.8890 - val_accuracy: 0.6856 - val_loss: 0.8357\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6524 - loss: 0.9110 - val_accuracy: 0.6926 - val_loss: 0.7712\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.6843 - loss: 0.8726 - val_accuracy: 0.7564 - val_loss: 0.7104\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7430 - loss: 0.7138 - val_accuracy: 0.7658 - val_loss: 0.6804\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2024)\n",
    "model = tf.keras.models.Sequential()# emty model\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[28, 28])) # input layer\n",
    "for layer in range(100):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\")) # hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\")) # output layer\n",
    "model.compile(\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "  metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bath Normalzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1460 - loss: 2.2334 - val_accuracy: 0.3012 - val_loss: 2.1025\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3786 - loss: 2.0886 - val_accuracy: 0.4978 - val_loss: 2.0204\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5006 - loss: 2.0121 - val_accuracy: 0.5504 - val_loss: 1.9533\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5349 - loss: 1.9495 - val_accuracy: 0.5550 - val_loss: 1.8937\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5391 - loss: 1.8919 - val_accuracy: 0.5554 - val_loss: 1.8362\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(2024)  # so that the results are reproducible\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(200, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\")) # output layer\n",
    "model.compile(\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "  metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Cliping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.7649 - loss: 0.6477 - val_accuracy: 0.7884 - val_loss: 0.5722\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7859 - loss: 0.5877 - val_accuracy: 0.7978 - val_loss: 0.5541\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.7962 - loss: 0.5550 - val_accuracy: 0.8072 - val_loss: 0.5443\n",
      "Epoch 4/5\n",
      "\u001b[1m  78/1719\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8086 - loss: 0.5399"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, clipvalue=1.0) #add clipvalue for up\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer= optimizer,\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster Opimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(seed=2024):\n",
    "    tf.random.set_seed(seed)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        tf.keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_and_train_model(optimizer):\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer= optimizer,\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.7880 - loss: 0.6313 - val_accuracy: 0.8040 - val_loss: 0.5819\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8054 - loss: 0.5785 - val_accuracy: 0.8106 - val_loss: 0.5823\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8203 - loss: 0.5590 - val_accuracy: 0.8200 - val_loss: 0.5616\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.5398 - val_accuracy: 0.8226 - val_loss: 0.5524\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8244 - loss: 0.5613 - val_accuracy: 0.8310 - val_loss: 0.5357\n"
     ]
    }
   ],
   "source": [
    "def build_model(seed=2024):\n",
    "    tf.random.set_seed(seed)\n",
    "    model = compile_model(\n",
    "      loss=\"sparse_categorical_crossentropy\",\n",
    "      optimizer=optimizer,\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "history = model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modentum  Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_and_train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_and_train_model\u001b[49m(optimizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_and_train_model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9)\n",
    "history = build_and_train_model(optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
