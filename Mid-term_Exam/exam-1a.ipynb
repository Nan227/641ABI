{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the first column is dependent variable $y$, other columns include independent variables. We would like to build appropriate models from predicting $y$.\n",
    "\n",
    "**Task 1**: \n",
    "1. Split the dataset into training (90%) and test set (10%). (1 pt)\n",
    "2. Use `StandardScaler` function in `sklearn.preprocessing` to standardize X variables. (2 pts)\n",
    "3. Perform linear regression to fit the training set, then calculate the test MSE. (2 pts)\n",
    "4. Perform 5-fold cross validation to choose a best model from the following 3 models. You need to obtain cross validation MSE. (5 pts)\n",
    "   - $y \\sim X1+X2$\n",
    "   - $y \\sim X1+X2+X3$\n",
    "   - $y \\sim X1+X2+X3+X4+X5$\n",
    "5. Calculate the test MSE by using the best model obtained above. You need to refit the model by using all the training set. Is this new MSE less than that in 3? (3 pts)\n",
    "\n",
    "**Task 2**\n",
    "1. Perform LASSO regression to select variables. Choose the best parameter $\\alpha$ using grid search. (3 pts)\n",
    "2. With the best parameter $\\alpha$, which variables are deleted (the variables with coefficient equal to 0)? (2 pts)\n",
    "3. Calculate the test MSE by using the LASSO model. (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280.510607</td>\n",
       "      <td>2.940073</td>\n",
       "      <td>8.644027</td>\n",
       "      <td>25.414066</td>\n",
       "      <td>74.719200</td>\n",
       "      <td>219.679873</td>\n",
       "      <td>645.874775</td>\n",
       "      <td>1898.918725</td>\n",
       "      <td>5582.958904</td>\n",
       "      <td>16414.304470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214.423378</td>\n",
       "      <td>3.495544</td>\n",
       "      <td>12.218826</td>\n",
       "      <td>42.711441</td>\n",
       "      <td>149.299709</td>\n",
       "      <td>521.883665</td>\n",
       "      <td>1824.267176</td>\n",
       "      <td>6376.805704</td>\n",
       "      <td>22290.403251</td>\n",
       "      <td>77917.079511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.866565</td>\n",
       "      <td>0.940760</td>\n",
       "      <td>0.885029</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.783276</td>\n",
       "      <td>0.736875</td>\n",
       "      <td>0.693222</td>\n",
       "      <td>0.652156</td>\n",
       "      <td>0.613522</td>\n",
       "      <td>0.577177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.064747</td>\n",
       "      <td>0.219043</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-68.229070</td>\n",
       "      <td>1.025095</td>\n",
       "      <td>1.050819</td>\n",
       "      <td>1.077189</td>\n",
       "      <td>1.104221</td>\n",
       "      <td>1.131931</td>\n",
       "      <td>1.160337</td>\n",
       "      <td>1.189455</td>\n",
       "      <td>1.219304</td>\n",
       "      <td>1.249902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        X1         X2         X3          X4          X5  \\\n",
       "0  280.510607  2.940073   8.644027  25.414066   74.719200  219.679873   \n",
       "1  214.423378  3.495544  12.218826  42.711441  149.299709  521.883665   \n",
       "2    7.866565  0.940760   0.885029   0.832600    0.783276    0.736875   \n",
       "3   21.064747  0.219043   0.047980   0.010510    0.002302    0.000504   \n",
       "4  -68.229070  1.025095   1.050819   1.077189    1.104221    1.131931   \n",
       "\n",
       "            X6           X7            X8            X9  \n",
       "0   645.874775  1898.918725   5582.958904  16414.304470  \n",
       "1  1824.267176  6376.805704  22290.403251  77917.079511  \n",
       "2     0.693222     0.652156      0.613522      0.577177  \n",
       "3     0.000110     0.000024      0.000005      0.000001  \n",
       "4     1.160337     1.189455      1.219304      1.249902  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mse: 2536.4404320357744\n",
      "test mse: 3167.606922457756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "X_train_std = std.fit_transform(X_train)\n",
    "X_test_std = std.transform(X_test)\n",
    "\n",
    "y_train = y_train.to_numpy().reshape(-1,1)\n",
    "y_test = y_test.to_numpy().reshape(-1,1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train_std, y_train)\n",
    "\n",
    "y_train_pred = lin_reg.predict(X_train_std)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "y_test_pred = lin_reg.predict(X_test_std)\n",
    "\n",
    "test_mse_1 = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"training mse: {train_mse}\")\n",
    "print(f\"test mse: {test_mse_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_mean_val_mse(model, X, y, K=5):\n",
    "    np.random.seed(2024)\n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    average_size = int(np.around(len(X)/K, 0))\n",
    "\n",
    "    train_mses, val_mses = [], []\n",
    "    for k in range(K):\n",
    "        if k<K-1:\n",
    "            test_indices = shuffled_indices[k*average_size:(k+1)*average_size]\n",
    "        else:\n",
    "            test_indices = shuffled_indices[-average_size:]    \n",
    "\n",
    "        # train_indices are indices that are not in test_indices\n",
    "        train_indices = shuffled_indices[[shuffled_indices[i] not in test_indices for i in range(len(shuffled_indices))]]\n",
    "\n",
    "        train_set, val_set = X[train_indices], X[test_indices]\n",
    "\n",
    "        y_train, y_val = y[train_indices], y[test_indices]\n",
    "\n",
    "        model.fit(train_set, y_train)\n",
    "        \n",
    "        # training mse\n",
    "        train_pred = model.predict(train_set)\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        train_mses.append(train_mse)\n",
    "        \n",
    "        # validation mse\n",
    "        val_pred = model.predict(val_set)\n",
    "        val_mse = mean_squared_error(y_val, val_pred)\n",
    "        val_mses.append(val_mse)\n",
    "\n",
    "    return np.mean(train_mses), np.mean(val_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_train_mse: 4202.7095100493925\n",
      "mean_val_mse: 4467.823686337683\n"
     ]
    }
   ],
   "source": [
    "# model Y~X1+X2\n",
    "cols = [0, 1]\n",
    "X_train_temp = X_train_std[:, cols]\n",
    "\n",
    "# model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "mean_train_mse, mean_val_mse = func_mean_val_mse(lin_reg, X_train_temp, y_train)\n",
    "\n",
    "print(f\"mean_train_mse: {mean_train_mse}\")\n",
    "print(f\"mean_val_mse: {mean_val_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_train_mse: 2617.9940874150643\n",
      "mean_val_mse: 2795.4552825553264\n"
     ]
    }
   ],
   "source": [
    "# model Y~X1+X2+X3\n",
    "cols = [0, 1, 2]\n",
    "X_train_temp = X_train_std[:, cols]\n",
    "\n",
    "# model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "mean_train_mse, mean_val_mse = func_mean_val_mse(lin_reg, X_train_temp, y_train)\n",
    "\n",
    "print(f\"mean_train_mse: {mean_train_mse}\")\n",
    "print(f\"mean_val_mse: {mean_val_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_train_mse: 2529.6049198223614\n",
      "mean_val_mse: 2733.8919921040706\n"
     ]
    }
   ],
   "source": [
    "# model Y~X1+X2+X3+X4+X5\n",
    "cols = [0, 1, 2, 3, 4]\n",
    "X_train_temp = X_train_std[:, cols]\n",
    "\n",
    "# model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "mean_train_mse, mean_val_mse = func_mean_val_mse(lin_reg, X_train_temp, y_train)\n",
    "\n",
    "print(f\"mean_train_mse: {mean_train_mse}\")\n",
    "print(f\"mean_val_mse: {mean_val_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So best model is Y~X1+X2+X3+X4+X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mse: 3144.056435679504\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "cols = [0, 1, 2, 3, 4]\n",
    "X_train_temp = X_train_std[:, cols]\n",
    "\n",
    "# model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_temp, y_train)\n",
    "\n",
    "# test mse \n",
    "X_test_temp = X_test_std[:,cols]\n",
    "y_test_pred = lin_reg.predict(X_test_temp)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"test_mse: {test_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "1. Perform LASSO regression to select variables. Choose the best parameter $\\alpha$ using grid search.\n",
    "2. Calculate the test MSE by using the LASSO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+05, tolerance: 1.258e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+05, tolerance: 1.234e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+05, tolerance: 1.304e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+05, tolerance: 1.248e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.808e+05, tolerance: 1.339e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+05, tolerance: 1.258e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.094e+04, tolerance: 1.234e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.692e+04, tolerance: 1.304e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.595e+04, tolerance: 1.248e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+05, tolerance: 1.339e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+04, tolerance: 1.258e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.626e+03, tolerance: 1.234e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.804e+03, tolerance: 1.304e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.853e+03, tolerance: 1.248e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.577e+03, tolerance: 1.339e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e+02, tolerance: 1.258e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+02, tolerance: 1.234e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+02, tolerance: 1.304e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e+03, tolerance: 1.597e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 0.01, 0.1, 1, 10, 100, 200, 300, 400]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 0.01, 0.1, 1, 10, 100, 200, 300, 400]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [0, 0.01, 0.1, 1, 10, 100, 200, 300, 400]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha': [0,0.01,0.1,1,10,100, 200, 300, 400]} # 0.1\n",
    "# params = {'alpha': [0.01,0.05, 0.1,0.5, 1]} # 0.1\n",
    "# params = {'alpha': [0.05, 0.08, 0.1,0.2, 0.3, 0.4, 0.5]} # 0.2\n",
    "# params = {'alpha': [0.1, 0.15, 0.2, 0.25, 0.3]} # 0.15\n",
    "# params = {'alpha': [0.15, 0.16, 0.17, 0.18, 0.19, 0.2]}  # 0.18\n",
    "\n",
    "gridcv_lasso_model = GridSearchCV(Lasso(),params,cv=5)\n",
    "gridcv_lasso_model.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridcv_lasso_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24.50463329,  181.06648081,    0.        ,  -36.43110234,\n",
       "       -105.97823825,  -50.24111262,   -0.        ,    0.        ,\n",
       "          1.6198043 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridcv_lasso_model.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3217.0527049253315"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lass_pred = gridcv_lasso_model.best_estimator_.predict(X_test_std)\n",
    "\n",
    "mean_squared_error(y_test, lass_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
